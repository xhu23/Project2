<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="weekday-report">WeekDay Report</h1>
<p>Xinyu Hu 6/30/2020</p>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#about-the-data">About the data</a></li>
<li><a href="#summarization">Summarization</a>
<ul>
<li><a href="#simple-statistics">Simple Statistics</a></li>
<li><a href="#simple-plots">Simple Plots</a></li>
<li><a href="#plot-with-response">Plot with Response</a></li>
</ul></li>
<li><a href="#modeling">Modeling</a>
<ul>
<li><a href="#ensemble-model">Ensemble model</a></li>
<li><a href="#linear-regression-model">Linear Regression Model</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>This is a practice project of ST558 course at NC State. The data is offered by <a href="https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity">UCI Machine Learning Repository</a>.<br />
The data set is made of statistics associsated with articles published by Mashable. It includes 61 attributes, among which are 58 predictive attributes, 2 non-predictive and 1 goal (reponse) field.<br />
The goal of this project, from my perspective, is practicing modeling using R with both linear model and non linear model.The purpose of this project is to find a relatively better way to predict <em>Number of Shares</em> of those articles, using the provided associated statistics.</p>
<h1 id="about-the-data">About the data</h1>
<p><strong>Row-wise, this analysis is about the weekday of</strong></p>
<pre><code>## [1] weekday_is_monday
</code></pre>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">colnames</span>(News)</a></code></pre></div>
<pre><code>##  [1] &quot;url&quot;                           &quot;timedelta&quot;                     &quot;n_tokens_title&quot;                &quot;n_tokens_content&quot;              &quot;n_unique_tokens&quot;              
##  [6] &quot;n_non_stop_words&quot;              &quot;n_non_stop_unique_tokens&quot;      &quot;num_hrefs&quot;                     &quot;num_self_hrefs&quot;                &quot;num_imgs&quot;                     
## [11] &quot;num_videos&quot;                    &quot;average_token_length&quot;          &quot;num_keywords&quot;                  &quot;data_channel_is_lifestyle&quot;     &quot;data_channel_is_entertainment&quot;
## [16] &quot;data_channel_is_bus&quot;           &quot;data_channel_is_socmed&quot;        &quot;data_channel_is_tech&quot;          &quot;data_channel_is_world&quot;         &quot;kw_min_min&quot;                   
## [21] &quot;kw_max_min&quot;                    &quot;kw_avg_min&quot;                    &quot;kw_min_max&quot;                    &quot;kw_max_max&quot;                    &quot;kw_avg_max&quot;                   
## [26] &quot;kw_min_avg&quot;                    &quot;kw_max_avg&quot;                    &quot;kw_avg_avg&quot;                    &quot;self_reference_min_shares&quot;     &quot;self_reference_max_shares&quot;    
## [31] &quot;self_reference_avg_sharess&quot;    &quot;weekday_is_monday&quot;             &quot;weekday_is_tuesday&quot;            &quot;weekday_is_wednesday&quot;          &quot;weekday_is_thursday&quot;          
## [36] &quot;weekday_is_friday&quot;             &quot;weekday_is_saturday&quot;           &quot;weekday_is_sunday&quot;             &quot;is_weekend&quot;                    &quot;LDA_00&quot;                       
## [41] &quot;LDA_01&quot;                        &quot;LDA_02&quot;                        &quot;LDA_03&quot;                        &quot;LDA_04&quot;                        &quot;global_subjectivity&quot;          
## [46] &quot;global_sentiment_polarity&quot;     &quot;global_rate_positive_words&quot;    &quot;global_rate_negative_words&quot;    &quot;rate_positive_words&quot;           &quot;rate_negative_words&quot;          
## [51] &quot;avg_positive_polarity&quot;         &quot;min_positive_polarity&quot;         &quot;max_positive_polarity&quot;         &quot;avg_negative_polarity&quot;         &quot;min_negative_polarity&quot;        
## [56] &quot;max_negative_polarity&quot;         &quot;title_subjectivity&quot;            &quot;title_sentiment_polarity&quot;      &quot;abs_title_subjectivity&quot;        &quot;abs_title_sentiment_polarity&quot; 
## [61] &quot;shares&quot;
</code></pre>
<p><strong>Column-wise, this analysis includes 61 fields.</strong> According to the <a href="https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity">data description</a>, from column #3 to columns #60 are the predictors. While I have no knowledge about each of them, I can see there are a couple of perspecives that we can group them.<br />
1) <em>Column 3 to Column 13</em> are all numeric predictors. Among them, Column 3 to Column Column 7, and column 12 are about tokens of the article; Column 8 to Column Column 11, and column 13 are about the links, image, video, and keywords of the articles.<br />
2) <em>Column 14 to Column 19</em> are all about the topic, or channel of the data. So here it will tag 7 types of channels: Lifestyle, Entertainment, Business, Social Media, Tech and World.<br />
3) <em>Column 20 to Column 28</em> are all about key word. For example, worst keyword, best keyword, average keyword, etc.<br />
4) <em>Column 29 to Column 31</em> are about self reference. They capture the min, avg and max shares of referenced atritles in mashable.<br />
5) <em>Colun 32 to Column 29</em> is aboue the timing of the article. Those are flags to tag out if the article is published in Monday to Sunday, and also if it’s on weekend.<br />
6) <em>Column 40 to Column 44</em> are about the Closeness to LDA topics, with topic 0 to topic 4 respectively.<br />
7) <em>Colum 45 to Column 60</em> are all about <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP)</a> result of the artcle. They include polarity, subjectivity, sentiment of the article.</p>
<p>To start the analysis, we first look at Monday data, and use Rmarkdown <em>Knit with Parameter</em> for all the weekdays. Also, a 70-30 split will be made for modeling training and testing. Last but not least, I choose to predict a binary response, which is dividing the shares into two groups (&lt; 1400 and &gt;=1400).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">News_modelscope[<span class="st">&quot;NoLessThan1400&quot;</span>] &lt;-<span class="st"> </span><span class="kw">ifelse</span>(News_modelscope<span class="op">$</span>shares <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="dv">1</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb4-2" title="2">News_modelscope<span class="op">$</span>NoLessThan1400 &lt;-<span class="st"> </span><span class="kw">as.factor</span>(News_modelscope<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb4-3" title="3"><span class="kw">set.seed</span>(<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb4-4" title="4">train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(News_modelscope), <span class="dt">size =</span> <span class="kw">nrow</span>(News_modelscope)<span class="op">*</span><span class="fl">0.7</span>)</a>
<a class="sourceLine" id="cb4-5" title="5">test &lt;-<span class="st"> </span>dplyr<span class="op">::</span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(News_modelscope), train)</a>
<a class="sourceLine" id="cb4-6" title="6">DataTrain &lt;-<span class="st"> </span>News_modelscope[train, ]</a>
<a class="sourceLine" id="cb4-7" title="7">DataTest &lt;-<span class="st"> </span>News_modelscope[test, ]</a></code></pre></div>
<h1 id="summarization">Summarization</h1>
<p>As all the predictors are numeric, now we can start to explore some feature of them.</p>
<h2 id="simple-statistics">Simple Statistics</h2>
<ol>
<li>Variables describing the tokens are of great interest of me. So I want to know the simple statistics before I jump into prediction (also I can check if there is any missing).</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1"><span class="kw">summary</span>(DataTrain[,<span class="dv">3</span><span class="op">:</span><span class="dv">7</span>])</a></code></pre></div>
<pre><code>##  n_tokens_title  n_tokens_content n_unique_tokens  n_non_stop_words n_non_stop_unique_tokens
##  Min.   : 2.00   Min.   :   0.0   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000          
##  1st Qu.: 9.00   1st Qu.: 249.0   1st Qu.:0.4748   1st Qu.:1.0000   1st Qu.:0.6288          
##  Median :10.00   Median : 400.0   Median :0.5424   Median :1.0000   Median :0.6918          
##  Mean   :10.39   Mean   : 543.5   Mean   :0.5319   Mean   :0.9708   Mean   :0.6741          
##  3rd Qu.:12.00   3rd Qu.: 715.5   3rd Qu.:0.6090   3rd Qu.:1.0000   3rd Qu.:0.7556          
##  Max.   :18.00   Max.   :7764.0   Max.   :0.9143   Max.   :1.0000   Max.   :1.0000
</code></pre>
<ol start="2">
<li>Another interesting perspectives are about the NLP metrics. So I perform summary function on them as well (also I can check if there is any missing):</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1"><span class="kw">summary</span>(DataTrain[,<span class="dv">47</span><span class="op">:</span><span class="dv">58</span>])</a></code></pre></div>
<pre><code>##  global_rate_positive_words global_rate_negative_words rate_positive_words rate_negative_words avg_positive_polarity min_positive_polarity max_positive_polarity
##  Min.   :0.00000            Min.   :0.000000           Min.   :0.0000      Min.   :0.0000      Min.   :0.0000        Min.   :0.00000       Min.   :0.0000       
##  1st Qu.:0.02857            1st Qu.:0.009569           1st Qu.:0.6000      1st Qu.:0.1842      1st Qu.:0.3042        1st Qu.:0.05000       1st Qu.:0.6000       
##  Median :0.03846            Median :0.015413           Median :0.7103      Median :0.2800      Median :0.3583        Median :0.10000       Median :0.8000       
##  Mean   :0.03931            Mean   :0.016679           Mean   :0.6820      Mean   :0.2886      Mean   :0.3529        Mean   :0.09405       Mean   :0.7596       
##  3rd Qu.:0.04969            3rd Qu.:0.021508           3rd Qu.:0.8000      3rd Qu.:0.3822      3rd Qu.:0.4115        3rd Qu.:0.10000       3rd Qu.:1.0000       
##  Max.   :0.12500            Max.   :0.092160           Max.   :1.0000      Max.   :1.0000      Max.   :1.0000        Max.   :1.00000       Max.   :1.0000       
##  avg_negative_polarity min_negative_polarity max_negative_polarity title_subjectivity title_sentiment_polarity
##  Min.   :-1.0000       Min.   :-1.000        Min.   :-1.0000       Min.   :0.0000     Min.   :-1.00000        
##  1st Qu.:-0.3277       1st Qu.:-0.700        1st Qu.:-0.1250       1st Qu.:0.0000     1st Qu.: 0.00000        
##  Median :-0.2505       Median :-0.500        Median :-0.1000       Median :0.1000     Median : 0.00000        
##  Mean   :-0.2575       Mean   :-0.516        Mean   :-0.1052       Mean   :0.2733     Mean   : 0.06672        
##  3rd Qu.:-0.1845       3rd Qu.:-0.300        3rd Qu.:-0.0500       3rd Qu.:0.5000     3rd Qu.: 0.13636        
##  Max.   : 0.0000       Max.   : 0.000        Max.   : 0.0000       Max.   :1.0000     Max.   : 1.00000
</code></pre>
<h2 id="simple-plots">Simple Plots</h2>
<ol>
<li>One group of predictors that could be very helpful is the channel for each articles. So Understanding how many articles in each channel will be a “good to know”.</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1">DataTrain[<span class="st">&quot;data_channel&quot;</span>] &lt;-<span class="st"> </span><span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_lifestyle<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Lifestyle&#39;</span>,</a>
<a class="sourceLine" id="cb9-2" title="2">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_entertainment<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Entertainment&#39;</span>,</a>
<a class="sourceLine" id="cb9-3" title="3">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_bus<span class="op">==</span><span class="dv">1</span>,<span class="st">&#39;Business&#39;</span>,</a>
<a class="sourceLine" id="cb9-4" title="4">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_socmed<span class="op">==</span><span class="dv">1</span>,<span class="st">&#39;Social Media&#39;</span>,</a>
<a class="sourceLine" id="cb9-5" title="5">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_tech<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Tech&#39;</span>,</a>
<a class="sourceLine" id="cb9-6" title="6">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_world<span class="op">==</span><span class="dv">1</span>,<span class="st">&quot;World&quot;</span>,<span class="ot">NA</span>))))))</a>
<a class="sourceLine" id="cb9-7" title="7"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb9-8" title="8">plot1&lt;-<span class="kw">ggplot</span>(<span class="dt">data=</span>DataTrain,<span class="kw">aes</span>(data_channel))</a>
<a class="sourceLine" id="cb9-9" title="9">plot1 <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">size=</span><span class="dv">2</span>)<span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Channels&quot;</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<ol start="2">
<li>Another interesting point to know before modeling is LDA topics distribution. So perform the same exploratory visualization here:</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="kw">library</span>(ggpubr)</a>
<a class="sourceLine" id="cb10-2" title="2"><span class="kw">ggarrange</span>(plot2, plot3, plot4, plot5, plot6, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h2 id="plot-with-response">Plot with Response</h2>
<ol>
<li>One interesting point is to look at the density/distribution of average token length by the flag of being shared more than 1,400 times or not:</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="kw">library</span>(wesanderson)</a>
<a class="sourceLine" id="cb11-2" title="2">plot7&lt;-<span class="st"> </span><span class="kw">ggplot</span>(DataTrain,<span class="kw">aes</span>(<span class="dt">x=</span>average_token_length, <span class="dt">fill=</span>NoLessThan1400)) </a>
<a class="sourceLine" id="cb11-3" title="3">plot7 <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..))<span class="op">+</span><span class="kw">geom_density</span>(<span class="dt">adjust=</span><span class="fl">0.25</span>,<span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Average Token Length By Share Flag&quot;</span>, <span class="dt">x =</span><span class="st">&quot;Average Token Length&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<ol start="2">
<li>Another intersting point is to look at number of images, to see if the density/distribution are different across the shaing flag (1 mean “Yes”, 0 means “No”):</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">library</span>(wesanderson)</a>
<a class="sourceLine" id="cb12-2" title="2">plot8&lt;-<span class="st"> </span><span class="kw">ggplot</span>(DataTrain,<span class="kw">aes</span>(<span class="dt">x=</span>n_tokens_title, <span class="dt">fill=</span>NoLessThan1400)) </a>
<a class="sourceLine" id="cb12-3" title="3">plot8 <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Title Token Count By Share Flag&quot;</span>,</a>
<a class="sourceLine" id="cb12-4" title="4">        <span class="dt">x =</span><span class="st">&quot;Title Token Count&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h1 id="modeling">Modeling</h1>
<h2 id="ensemble-model">Ensemble model</h2>
<p>Here, I pick bagged tree as preferred approach. The model training and tuning is based on <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#:~:text=Cross%2Dvalidation%2C%20sometimes%20called%20rotation,to%20an%20independent%20data%20set."><strong>Cross-validation</strong></a>. This method first splits the whole dataset into k folds (here I pick 10). Then, it trains model using 9 folds of data and tuning with 1 remaining fold of data. With inherent cross validation, The CV method will make very good use of existing data, and have relatively good result.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb13-2" title="2">trCtrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb13-3" title="3">bagfitTree&lt;-<span class="st"> </span><span class="kw">train</span> (NoLessThan1400 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> DataTrain[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">60</span>,<span class="dv">62</span>)], <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,</a>
<a class="sourceLine" id="cb13-4" title="4">                       <span class="dt">trControl =</span> trCtrl, <span class="dt">metric =</span> <span class="st">&quot;Accuracy&quot;</span>)</a>
<a class="sourceLine" id="cb13-5" title="5">bagfitTree</a></code></pre></div>
<pre><code>## Bagged CART 
## 
## 5328 samples
##   58 predictor
##    2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4796, 4795, 4795, 4795, 4794, 4795, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.6387014  0.2772857
</code></pre>
<p>With the bagged tree model, we can apply to the <strong>training dataset</strong> to see how good (<em>overfitting</em>) it is:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">BaggedTree_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(bagfitTree, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTrain,<span class="op">-</span>NoLessThan1400))</a>
<a class="sourceLine" id="cb15-2" title="2">Result1 &lt;-<span class="st"> </span><span class="kw">table</span>(BaggedTree_TrainingDatePrediction,DataTrain<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb15-3" title="3">Result1</a></code></pre></div>
<pre><code>##                                  
## BaggedTree_TrainingDatePrediction    0    1
##                                 0 2309    2
##                                 1    2 2349
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1">misClass1 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result1))<span class="op">/</span><span class="kw">sum</span>(Result1)</a>
<a class="sourceLine" id="cb17-2" title="2">misClass1</a></code></pre></div>
<pre><code>## [1] 0.0008580009
</code></pre>
<p>Also, we can apply the model to the <strong>test dataset</strong> to see how good (<em>honest check</em>) it is:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1">BaggedTree_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(bagfitTree, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTest,<span class="op">-</span>NoLessThan1400))</a>
<a class="sourceLine" id="cb19-2" title="2">Result2 &lt;-<span class="st"> </span><span class="kw">table</span>(BaggedTree_TestDatePrediction,DataTest<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb19-3" title="3">Result2</a></code></pre></div>
<pre><code>##                              
## BaggedTree_TestDatePrediction   0   1
##                             0 717 258
##                             1 242 782
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">misClass2 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result2))<span class="op">/</span><span class="kw">sum</span>(Result2)</a>
<a class="sourceLine" id="cb21-2" title="2">misClass2</a></code></pre></div>
<pre><code>## [1] 0.2501251
</code></pre>
<h2 id="linear-regression-model">Linear Regression Model</h2>
<p>I decide to use stepwise selection to choose the best regression model, with AIC as the fit measurement. <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion"><strong>Akaike Information Criterion</strong></a> is a very handy measurement to compare the model fit. It starts with a set of candidate models, and then find the models’ corresponding AIC values. Then it picks the model that minimizes the information loss among the candidate models. It penalize number of predictors to avoid overfitting.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb23-2" title="2">full_model &lt;-<span class="st"> </span><span class="kw">glm</span>(NoLessThan1400 <span class="op">~</span>., <span class="dt">data =</span> DataTrain[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">60</span>,<span class="dv">62</span>)], <span class="dt">family=</span>binomial)</a>
<a class="sourceLine" id="cb23-3" title="3">step_model &lt;-<span class="st"> </span><span class="kw">stepAIC</span>(full_model, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb23-4" title="4"><span class="kw">summary</span>(step_model)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = NoLessThan1400 ~ num_hrefs + num_self_hrefs + num_keywords + 
##     data_channel_is_lifestyle + data_channel_is_entertainment + 
##     data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
##     kw_avg_min + kw_min_max + kw_max_max + kw_max_avg + kw_avg_avg + 
##     self_reference_max_shares + self_reference_avg_sharess + 
##     LDA_00 + LDA_01 + LDA_02 + LDA_03 + global_subjectivity + 
##     global_sentiment_polarity + rate_negative_words + avg_negative_polarity + 
##     max_negative_polarity + title_subjectivity + title_sentiment_polarity + 
##     abs_title_subjectivity, family = binomial, data = DataTrain[, 
##     c(3:60, 62)])
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8992  -1.0358   0.4684   1.0520   2.0821  
## 
## Coefficients:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                   -1.342e+00  2.988e-01  -4.491 7.08e-06 ***
## num_hrefs                      1.427e-02  3.375e-03   4.230 2.34e-05 ***
## num_self_hrefs                -1.822e-02  8.957e-03  -2.034 0.041997 *  
## num_keywords                   7.865e-02  1.719e-02   4.574 4.78e-06 ***
## data_channel_is_lifestyle     -2.738e-01  1.776e-01  -1.542 0.123086    
## data_channel_is_entertainment -4.477e-01  1.118e-01  -4.006 6.18e-05 ***
## data_channel_is_bus           -4.987e-01  1.618e-01  -3.083 0.002049 ** 
## data_channel_is_socmed         8.526e-01  1.714e-01   4.975 6.53e-07 ***
## data_channel_is_tech           3.237e-01  1.423e-01   2.276 0.022866 *  
## kw_avg_min                     1.549e-04  7.623e-05   2.033 0.042088 *  
## kw_min_max                    -1.224e-06  6.144e-07  -1.991 0.046446 *  
## kw_max_max                    -7.785e-07  1.497e-07  -5.200 1.99e-07 ***
## kw_max_avg                    -8.561e-05  1.084e-05  -7.901 2.77e-15 ***
## kw_avg_avg                     6.329e-04  5.160e-05  12.267  &lt; 2e-16 ***
## self_reference_max_shares     -4.969e-06  2.864e-06  -1.735 0.082801 .  
## self_reference_avg_sharess     1.705e-05  5.499e-06   3.100 0.001936 ** 
## LDA_00                         6.748e-01  2.302e-01   2.932 0.003367 ** 
## LDA_01                        -6.504e-01  2.377e-01  -2.736 0.006220 ** 
## LDA_02                        -9.201e-01  2.184e-01  -4.213 2.52e-05 ***
## LDA_03                        -7.330e-01  2.141e-01  -3.423 0.000619 ***
## global_subjectivity            5.340e-01  3.749e-01   1.424 0.154358    
## global_sentiment_polarity     -1.301e+00  5.382e-01  -2.417 0.015669 *  
## rate_negative_words           -7.438e-01  2.899e-01  -2.566 0.010285 *  
## avg_negative_polarity         -6.669e-01  3.722e-01  -1.792 0.073150 .  
## max_negative_polarity          7.718e-01  4.171e-01   1.850 0.064256 .  
## title_subjectivity             2.306e-01  1.120e-01   2.058 0.039590 *  
## title_sentiment_polarity       1.833e-01  1.219e-01   1.504 0.132640    
## abs_title_subjectivity         4.007e-01  1.859e-01   2.155 0.031171 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 7384.8  on 5327  degrees of freedom
## Residual deviance: 6712.8  on 5300  degrees of freedom
## AIC: 6768.8
## 
## Number of Fisher Scoring iterations: 4
</code></pre>
<p>Same as bagged tree model, we can apply the final model coming out from stepwise select to the <strong>training dataset</strong> to see how good (<em>overfitting</em>) it is:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1">StepModel_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(step_model, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTrain,<span class="op">-</span>NoLessThan1400),<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb25-2" title="2">StepModel_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(StepModel_TrainingDatePrediction <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb25-3" title="3">Result3 &lt;-<span class="st"> </span><span class="kw">table</span>(StepModel_TrainingDatePrediction,DataTrain<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb25-4" title="4">Result3 </a></code></pre></div>
<pre><code>##                                 
## StepModel_TrainingDatePrediction    0    1
##                                0 1501  849
##                                1  810 1502
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1">misClass3 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result3))<span class="op">/</span><span class="kw">sum</span>(Result3)</a>
<a class="sourceLine" id="cb27-2" title="2">misClass3</a></code></pre></div>
<pre><code>## [1] 0.3558559
</code></pre>
<p>Also, we can apply the model to the <strong>test dataset</strong> to see how good (<em>honest check</em>) it is:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1">StepModel_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(step_model, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTest,<span class="op">-</span>NoLessThan1400), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb29-2" title="2">StepModel_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(StepModel_TestDatePrediction <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb29-3" title="3">Result4 &lt;-<span class="st"> </span><span class="kw">table</span>(StepModel_TestDatePrediction,DataTest<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb29-4" title="4">Result4</a></code></pre></div>
<pre><code>##                             
## StepModel_TestDatePrediction   0   1
##                            0 610 393
##                            1 349 647
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1">misClass4 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result4))<span class="op">/</span><span class="kw">sum</span>(Result4)</a>
<a class="sourceLine" id="cb31-2" title="2">misClass4</a></code></pre></div>
<pre><code>## [1] 0.3711856
</code></pre>
<h1 id="conclusion">Conclusion</h1>
<p>Based on my knowledge, The miss-classification rate of the test data set is a very solid comparison measurement. So I will tag the model with smallest test data miss-classification rate as the final model.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"> <span class="cf">if</span>(misClass2 <span class="op">&gt;=</span><span class="st"> </span>misClass4){</a>
<a class="sourceLine" id="cb33-2" title="2"> FinalModel &lt;-bagfitTree</a>
<a class="sourceLine" id="cb33-3" title="3"><span class="kw">noquote</span>(<span class="st">&quot;The Better Model is Bagged Tree Model&quot;</span>)</a>
<a class="sourceLine" id="cb33-4" title="4"> }<span class="cf">else</span>{</a>
<a class="sourceLine" id="cb33-5" title="5"> FinalModel &lt;-<span class="st"> </span>step_model</a>
<a class="sourceLine" id="cb33-6" title="6"><span class="kw">noquote</span>(<span class="st">&quot;The Better Model is (Step) Logistic Regression Model&quot;</span>)}</a></code></pre></div>
<pre><code>## [1] The Better Model is (Step) Logistic Regression Model
</code></pre>
<p>Beyond this project, I think a better approach would be replicate the whole process 100 times, obtain the mis-classification rate of both model 100 times. Then compare to see how many times that Bagged Tree beats logistric regression model, and how many times the other way around. That would be very helpful to determine the stability of both models performance.</p>

</body>
</html>
