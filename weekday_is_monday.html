<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="rmarkdown">RMarkDown</h1>
<p>Xinyu Hu 6/28/2020</p>
<ul>
<li><a href="#about-the-data">About the data</a></li>
<li><a href="#summarization">Summarization</a>
<ul>
<li><a href="#simple-statistics">Simple Statistics</a></li>
<li><a href="#simple-plots">Simple Plots</a></li>
</ul></li>
<li><a href="#modeling">Modeling</a>
<ul>
<li><a href="#ensemble-model">Ensemble model</a></li>
<li><a href="#linear-regression-model">Linear Regression Model</a></li>
<li><a href="#model-selection">Model Selection</a></li>
</ul></li>
</ul>
<p>#Introduction</p>
<p>This is a practice project of ST558 course at NC State. The data is offered by <a href="https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity">UCI Machine Learning Repository</a>.<br />
The data set is made of statistics associsated with articles published by Mashable. It includes 61 attributes, among which are 58 predictive attributes, 2 non-predictive and 1 goal (reponse) field.<br />
The goal of this project, from my perspective, is practicing modeling using R with both linear model and non linear model.The purpose of this project is to find a relatively better way to predict <em>Number of Shares</em> of those articles, using the provided associated statistics.</p>
<h1 id="about-the-data">About the data</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">colnames</span>(News)</a></code></pre></div>
<pre><code>##  [1] &quot;url&quot;                           &quot;timedelta&quot;                     &quot;n_tokens_title&quot;                &quot;n_tokens_content&quot;             
##  [5] &quot;n_unique_tokens&quot;               &quot;n_non_stop_words&quot;              &quot;n_non_stop_unique_tokens&quot;      &quot;num_hrefs&quot;                    
##  [9] &quot;num_self_hrefs&quot;                &quot;num_imgs&quot;                      &quot;num_videos&quot;                    &quot;average_token_length&quot;         
## [13] &quot;num_keywords&quot;                  &quot;data_channel_is_lifestyle&quot;     &quot;data_channel_is_entertainment&quot; &quot;data_channel_is_bus&quot;          
## [17] &quot;data_channel_is_socmed&quot;        &quot;data_channel_is_tech&quot;          &quot;data_channel_is_world&quot;         &quot;kw_min_min&quot;                   
## [21] &quot;kw_max_min&quot;                    &quot;kw_avg_min&quot;                    &quot;kw_min_max&quot;                    &quot;kw_max_max&quot;                   
## [25] &quot;kw_avg_max&quot;                    &quot;kw_min_avg&quot;                    &quot;kw_max_avg&quot;                    &quot;kw_avg_avg&quot;                   
## [29] &quot;self_reference_min_shares&quot;     &quot;self_reference_max_shares&quot;     &quot;self_reference_avg_sharess&quot;    &quot;weekday_is_monday&quot;            
## [33] &quot;weekday_is_tuesday&quot;            &quot;weekday_is_wednesday&quot;          &quot;weekday_is_thursday&quot;           &quot;weekday_is_friday&quot;            
## [37] &quot;weekday_is_saturday&quot;           &quot;weekday_is_sunday&quot;             &quot;is_weekend&quot;                    &quot;LDA_00&quot;                       
## [41] &quot;LDA_01&quot;                        &quot;LDA_02&quot;                        &quot;LDA_03&quot;                        &quot;LDA_04&quot;                       
## [45] &quot;global_subjectivity&quot;           &quot;global_sentiment_polarity&quot;     &quot;global_rate_positive_words&quot;    &quot;global_rate_negative_words&quot;   
## [49] &quot;rate_positive_words&quot;           &quot;rate_negative_words&quot;           &quot;avg_positive_polarity&quot;         &quot;min_positive_polarity&quot;        
## [53] &quot;max_positive_polarity&quot;         &quot;avg_negative_polarity&quot;         &quot;min_negative_polarity&quot;         &quot;max_negative_polarity&quot;        
## [57] &quot;title_subjectivity&quot;            &quot;title_sentiment_polarity&quot;      &quot;abs_title_subjectivity&quot;        &quot;abs_title_sentiment_polarity&quot; 
## [61] &quot;shares&quot;
</code></pre>
<p>As we know before, there are 61 fields. According to the <a href="https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity">data description</a>, from column #3 to columns #60 are the predictors. While I have no knowledge about each of them, I can see there are a couple of perspecives that we can group them.<br />
1) <em>Column 3 to Column 13</em> are all numeric predictors. Among them, Column 3 to Column Column 7, and column 12 are about tokens of the article; Column 8 to Column Column 11, and column 13 are about the links, image, video, and keywords of the articles.<br />
2) <em>Column 14 to Column 19</em> are all about the topic, or channel of the data. So here it will tag 7 types of channels: Lifestyle, Entertainment, Business, Social Media, Tech and World.<br />
3) <em>Column 20 to Column 28</em> are all about key word. For example, worst keyword, best keyword, average keyword, etc.<br />
4) <em>Column 29 to Column 31</em> are about self reference. They capture the min, avg and max shares of referenced atritles in mashable.<br />
5) <em>Colun 32 to Column 29</em> is aboue the timing of the article. Those are flags to tag out if the article is published in Monday to Sunday, and also if it’s on weekend.<br />
6) <em>Column 40 to Column 44</em> are about the Closeness to LDA topics, with topic 0 to topic 4 respectively.<br />
7) <em>Colum 45 to Column 60</em> are all about <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP)</a> result of the artcle. They include polarity, subjectivity, sentiment of the article.</p>
<p>To start the analysis, we first look at Monday data, and use Rmarkdown <em>Knit with Parameter</em> for all the weekdays. Also, a 70-30 split will be made for modeling training and testing. Last but not least, I choose to predict a binary response, which is dividing the shares into two groups (&lt; 1400 and &gt;=1400).</p>
<h1 id="summarization">Summarization</h1>
<p>As all the predictors are numeric, now we can start to explore some feature of them.</p>
<h2 id="simple-statistics">Simple Statistics</h2>
<ol>
<li>Variables describing the tokens are of great interest of me. So I want to know the simple statistics before I jump into prediction (also I can check if there is any missing).</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">summary</span>(DataTrain[,<span class="dv">3</span><span class="op">:</span><span class="dv">7</span>])</a></code></pre></div>
<pre><code>##  n_tokens_title n_tokens_content n_unique_tokens  n_non_stop_words n_non_stop_unique_tokens
##  Min.   : 2.0   Min.   :   0     Min.   :0.0000   Min.   :0.0000   Min.   :0.0000          
##  1st Qu.: 9.0   1st Qu.: 251     1st Qu.:0.4738   1st Qu.:1.0000   1st Qu.:0.6286          
##  Median :10.0   Median : 406     Median :0.5415   Median :1.0000   Median :0.6916          
##  Mean   :10.4   Mean   : 546     Mean   :0.5307   Mean   :0.9707   Mean   :0.6734          
##  3rd Qu.:12.0   3rd Qu.: 718     3rd Qu.:0.6083   3rd Qu.:1.0000   3rd Qu.:0.7553          
##  Max.   :18.0   Max.   :7764     Max.   :0.9143   Max.   :1.0000   Max.   :1.0000
</code></pre>
<ol start="2">
<li>Another interesting perspectives are about the NLP metrics. So I perform summary function on them as well (also I can check if there is any missing):</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1"><span class="kw">summary</span>(DataTrain[,<span class="dv">47</span><span class="op">:</span><span class="dv">58</span>])</a></code></pre></div>
<pre><code>##  global_rate_positive_words global_rate_negative_words rate_positive_words rate_negative_words avg_positive_polarity min_positive_polarity
##  Min.   :0.00000            Min.   :0.000000           Min.   :0.0000      Min.   :0.0000      Min.   :0.0000        Min.   :0.00000      
##  1st Qu.:0.02847            1st Qu.:0.009646           1st Qu.:0.6000      1st Qu.:0.1852      1st Qu.:0.3047        1st Qu.:0.05000      
##  Median :0.03856            Median :0.015416           Median :0.7097      Median :0.2800      Median :0.3584        Median :0.10000      
##  Mean   :0.03926            Mean   :0.016723           Mean   :0.6812      Mean   :0.2894      Mean   :0.3533        Mean   :0.09432      
##  3rd Qu.:0.04983            3rd Qu.:0.021599           3rd Qu.:0.8000      3rd Qu.:0.3846      3rd Qu.:0.4119        3rd Qu.:0.10000      
##  Max.   :0.12500            Max.   :0.092160           Max.   :1.0000      Max.   :1.0000      Max.   :1.0000        Max.   :1.00000      
##  max_positive_polarity avg_negative_polarity min_negative_polarity max_negative_polarity title_subjectivity title_sentiment_polarity
##  Min.   :0.0000        Min.   :-1.0000       Min.   :-1.0000       Min.   :-1.0000       Min.   :0.0000     Min.   :-1.00000        
##  1st Qu.:0.6000        1st Qu.:-0.3288       1st Qu.:-0.7000       1st Qu.:-0.1250       1st Qu.:0.0000     1st Qu.: 0.00000        
##  Median :0.8000        Median :-0.2511       Median :-0.5000       Median :-0.1000       Median :0.1000     Median : 0.00000        
##  Mean   :0.7602        Mean   :-0.2588       Mean   :-0.5188       Mean   :-0.1055       Mean   :0.2733     Mean   : 0.06727        
##  3rd Qu.:1.0000        3rd Qu.:-0.1852       3rd Qu.:-0.3000       3rd Qu.:-0.0500       3rd Qu.:0.5000     3rd Qu.: 0.13636        
##  Max.   :1.0000        Max.   : 0.0000       Max.   : 0.0000       Max.   : 0.0000       Max.   :1.0000     Max.   : 1.00000
</code></pre>
<h2 id="simple-plots">Simple Plots</h2>
<ol>
<li>One group of predictors that could be very helpful is the channel for each articles. So Understanding how many articles in each channel will be a “good to know”.</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">DataTrain[<span class="st">&quot;data_channel&quot;</span>] &lt;-<span class="st"> </span><span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_lifestyle<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Lifestyle&#39;</span>,</a>
<a class="sourceLine" id="cb7-2" title="2">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_entertainment<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Entertainment&#39;</span>,</a>
<a class="sourceLine" id="cb7-3" title="3">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_bus<span class="op">==</span><span class="dv">1</span>,<span class="st">&#39;Business&#39;</span>,</a>
<a class="sourceLine" id="cb7-4" title="4">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_socmed<span class="op">==</span><span class="dv">1</span>,<span class="st">&#39;Social Media&#39;</span>,</a>
<a class="sourceLine" id="cb7-5" title="5">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_tech<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Tech&#39;</span>,</a>
<a class="sourceLine" id="cb7-6" title="6">                             <span class="kw">ifelse</span>(DataTrain<span class="op">$</span>data_channel_is_world<span class="op">==</span><span class="dv">1</span>,<span class="st">&quot;World&quot;</span>,<span class="ot">NA</span>))))))</a>
<a class="sourceLine" id="cb7-7" title="7"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb7-8" title="8">plot1&lt;-<span class="kw">ggplot</span>(<span class="dt">data=</span>DataTrain,<span class="kw">aes</span>(data_channel))</a>
<a class="sourceLine" id="cb7-9" title="9">plot1 <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">size=</span><span class="dv">2</span>)<span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Channels&quot;</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<ol start="2">
<li>Another interesting point to know before modeling is LDA topics distribution. So perform the same exploratory visualization here:</li>
</ol>
<!-- end list -->

<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">library</span>(ggpubr)</a>
<a class="sourceLine" id="cb8-2" title="2"><span class="kw">ggarrange</span>(plot2, plot3, plot4, plot5, plot6, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h1 id="modeling">Modeling</h1>
<h2 id="ensemble-model">Ensemble model</h2>
<p>Here, I pick bagged tree as preferred approach.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb9-2" title="2">trCtrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb9-3" title="3">bagfitTree&lt;-<span class="st"> </span><span class="kw">train</span> (NoLessThan1400 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> DataTrain[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">60</span>,<span class="dv">62</span>)], <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,</a>
<a class="sourceLine" id="cb9-4" title="4">                       <span class="dt">trControl =</span> trCtrl, <span class="dt">metric =</span> <span class="st">&quot;Accuracy&quot;</span>)</a>
<a class="sourceLine" id="cb9-5" title="5">bagfitTree</a></code></pre></div>
<pre><code>## Bagged CART 
## 
## 5328 samples
##   58 predictor
##    2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4796, 4795, 4795, 4795, 4794, 4795, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.6387014  0.2772857
</code></pre>
<p>With the bagged tree model, we can apply to the training dataset to see how good it is:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1">BaggedTree_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(bagfitTree, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTrain,<span class="op">-</span>NoLessThan1400))</a>
<a class="sourceLine" id="cb11-2" title="2">Result1 &lt;-<span class="st"> </span><span class="kw">table</span>(BaggedTree_TrainingDatePrediction,DataTrain<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb11-3" title="3">Result1</a></code></pre></div>
<pre><code>##                                  
## BaggedTree_TrainingDatePrediction    0    1
##                                 0 2619    3
##                                 1    2 2704
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1">misClass1 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result1))<span class="op">/</span><span class="kw">sum</span>(Result1)</a>
<a class="sourceLine" id="cb13-2" title="2">misClass1</a></code></pre></div>
<pre><code>## [1] 0.0009384384
</code></pre>
<p>Also, we can apply the model to the test dataset to see how good it is:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">BaggedTree_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(bagfitTree, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTest,<span class="op">-</span>NoLessThan1400))</a>
<a class="sourceLine" id="cb15-2" title="2">Result2 &lt;-<span class="st"> </span><span class="kw">table</span>(BaggedTree_TestDatePrediction,DataTest<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb15-3" title="3">Result2</a></code></pre></div>
<pre><code>##                              
## BaggedTree_TestDatePrediction   0   1
##                             0 407 257
##                             1 242 427
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1">misClass2 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result2))<span class="op">/</span><span class="kw">sum</span>(Result2)</a>
<a class="sourceLine" id="cb17-2" title="2">misClass2</a></code></pre></div>
<pre><code>## [1] 0.3743436
</code></pre>
<h2 id="linear-regression-model">Linear Regression Model</h2>
<p>I decide to use Stepwise selection to choose the best regression model, with AIC as the fit measurement.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb19-2" title="2">full_model &lt;-<span class="st"> </span><span class="kw">glm</span>(NoLessThan1400 <span class="op">~</span>., <span class="dt">data =</span> DataTrain[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">60</span>,<span class="dv">62</span>)], <span class="dt">family=</span>binomial)</a>
<a class="sourceLine" id="cb19-3" title="3">step_model &lt;-<span class="st"> </span><span class="kw">stepAIC</span>(full_model, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb19-4" title="4"><span class="kw">summary</span>(step_model)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = NoLessThan1400 ~ num_hrefs + num_self_hrefs + num_keywords + 
##     data_channel_is_lifestyle + data_channel_is_entertainment + 
##     data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + 
##     kw_avg_min + kw_min_max + kw_max_max + kw_max_avg + kw_avg_avg + 
##     self_reference_max_shares + self_reference_avg_sharess + 
##     LDA_00 + LDA_01 + LDA_02 + LDA_03 + global_subjectivity + 
##     global_sentiment_polarity + rate_negative_words + avg_negative_polarity + 
##     max_negative_polarity + title_subjectivity + title_sentiment_polarity + 
##     abs_title_subjectivity, family = binomial, data = DataTrain[, 
##     c(3:60, 62)])
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8992  -1.0358   0.4684   1.0520   2.0821  
## 
## Coefficients:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                   -1.342e+00  2.988e-01  -4.491 7.08e-06 ***
## num_hrefs                      1.427e-02  3.375e-03   4.230 2.34e-05 ***
## num_self_hrefs                -1.822e-02  8.957e-03  -2.034 0.041997 *  
## num_keywords                   7.865e-02  1.719e-02   4.574 4.78e-06 ***
## data_channel_is_lifestyle     -2.738e-01  1.776e-01  -1.542 0.123086    
## data_channel_is_entertainment -4.477e-01  1.118e-01  -4.006 6.18e-05 ***
## data_channel_is_bus           -4.987e-01  1.618e-01  -3.083 0.002049 ** 
## data_channel_is_socmed         8.526e-01  1.714e-01   4.975 6.53e-07 ***
## data_channel_is_tech           3.237e-01  1.423e-01   2.276 0.022866 *  
## kw_avg_min                     1.549e-04  7.623e-05   2.033 0.042088 *  
## kw_min_max                    -1.224e-06  6.144e-07  -1.991 0.046446 *  
## kw_max_max                    -7.785e-07  1.497e-07  -5.200 1.99e-07 ***
## kw_max_avg                    -8.561e-05  1.084e-05  -7.901 2.77e-15 ***
## kw_avg_avg                     6.329e-04  5.160e-05  12.267  &lt; 2e-16 ***
## self_reference_max_shares     -4.969e-06  2.864e-06  -1.735 0.082801 .  
## self_reference_avg_sharess     1.705e-05  5.499e-06   3.100 0.001936 ** 
## LDA_00                         6.748e-01  2.302e-01   2.932 0.003367 ** 
## LDA_01                        -6.504e-01  2.377e-01  -2.736 0.006220 ** 
## LDA_02                        -9.201e-01  2.184e-01  -4.213 2.52e-05 ***
## LDA_03                        -7.330e-01  2.141e-01  -3.423 0.000619 ***
## global_subjectivity            5.340e-01  3.749e-01   1.424 0.154358    
## global_sentiment_polarity     -1.301e+00  5.382e-01  -2.417 0.015669 *  
## rate_negative_words           -7.438e-01  2.899e-01  -2.566 0.010285 *  
## avg_negative_polarity         -6.669e-01  3.722e-01  -1.792 0.073150 .  
## max_negative_polarity          7.718e-01  4.171e-01   1.850 0.064256 .  
## title_subjectivity             2.306e-01  1.120e-01   2.058 0.039590 *  
## title_sentiment_polarity       1.833e-01  1.219e-01   1.504 0.132640    
## abs_title_subjectivity         4.007e-01  1.859e-01   2.155 0.031171 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 7384.8  on 5327  degrees of freedom
## Residual deviance: 6712.8  on 5300  degrees of freedom
## AIC: 6768.8
## 
## Number of Fisher Scoring iterations: 4
</code></pre>
<p>Same as bagged tree model, we can apply the final model coming out from stepwise select to the training dataset to see how good it is:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">StepModel_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(step_model, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTrain,<span class="op">-</span>NoLessThan1400),<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb21-2" title="2">StepModel_TrainingDatePrediction &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(StepModel_TrainingDatePrediction <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb21-3" title="3">Result3 &lt;-<span class="st"> </span><span class="kw">table</span>(StepModel_TrainingDatePrediction,DataTrain<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb21-4" title="4">Result3 </a></code></pre></div>
<pre><code>##                                 
## StepModel_TrainingDatePrediction    0    1
##                                0 1703  976
##                                1  918 1731
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1">misClass3 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result3))<span class="op">/</span><span class="kw">sum</span>(Result3)</a>
<a class="sourceLine" id="cb23-2" title="2">misClass3</a></code></pre></div>
<pre><code>## [1] 0.3554805
</code></pre>
<p>Also, we can apply the model to the test dataset to see how good it is:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1">StepModel_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">predict</span>(step_model, <span class="dt">newdata=</span>dplyr<span class="op">::</span><span class="kw">select</span>(DataTest,<span class="op">-</span>NoLessThan1400), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb25-2" title="2">StepModel_TestDatePrediction &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(StepModel_TestDatePrediction <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb25-3" title="3">Result4 &lt;-<span class="st"> </span><span class="kw">table</span>(StepModel_TestDatePrediction,DataTest<span class="op">$</span>NoLessThan1400)</a>
<a class="sourceLine" id="cb25-4" title="4">Result4</a></code></pre></div>
<pre><code>##                             
## StepModel_TestDatePrediction   0   1
##                            0 408 266
##                            1 241 418
</code></pre>
<p>The associated miss-classification rate is:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1">misClass4 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(Result4))<span class="op">/</span><span class="kw">sum</span>(Result4)</a>
<a class="sourceLine" id="cb27-2" title="2">misClass4</a></code></pre></div>
<pre><code>## [1] 0.3803451
</code></pre>
<h2 id="model-selection">Model Selection</h2>
<p>Based on my knowledge, The miss-classification rate of the test data set is a very solid comparison measurement. So I will tag the model with smallest test data miss-classification rate as the final model.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1"> <span class="cf">if</span>(misClass2 <span class="op">&gt;=</span><span class="st"> </span>misClass4){</a>
<a class="sourceLine" id="cb29-2" title="2"> FinalModel &lt;-bagfitTree</a>
<a class="sourceLine" id="cb29-3" title="3"> <span class="kw">print</span>(<span class="st">&quot;The Better Model is Bagged Tree Model&quot;</span>)</a>
<a class="sourceLine" id="cb29-4" title="4"> }<span class="cf">else</span>{</a>
<a class="sourceLine" id="cb29-5" title="5"> FinalModel &lt;-<span class="st"> </span>step_model</a>
<a class="sourceLine" id="cb29-6" title="6"><span class="kw">print</span>(<span class="st">&quot;The Better Model is Bagged Tree Model&quot;</span>)}</a></code></pre></div>
<pre><code>## [1] &quot;The Better Model is Bagged Tree Model&quot;
</code></pre>

</body>
</html>
